{
	"jobConfig": {
		"name": "flight-aggregation-job",
		"description": "",
		"role": "arn:aws:iam::293732298754:role/glue-flight-job-role",
		"command": "glueetl",
		"version": "5.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 2,
		"maxCapacity": 2,
		"jobRunQueuingEnabled": false,
		"maxRetries": 0,
		"timeout": 480,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "flight-aggregation-job.py",
		"scriptLocation": "s3://aws-glue-assets-293732298754-us-east-1/scripts/",
		"language": "python-3",
		"spark": true,
		"sparkConfiguration": "standard",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2025-10-25T22:07:48.778Z",
		"developerMode": true,
		"connectionsList": [],
		"temporaryDirectory": "s3://aws-glue-assets-293732298754-us-east-1/temporary/",
		"glueHiveMetastore": true,
		"etlAutoTuning": true,
		"metrics": true,
		"observabilityMetrics": true,
		"bookmark": "job-bookmark-disable",
		"sparkPath": "s3://aws-glue-assets-293732298754-us-east-1/sparkHistoryLogs/",
		"flexExecution": false,
		"minFlexWorkers": null,
		"maintenanceWindow": null,
		"pythonPath": null
	},
	"dag": {},
	"hasBeenSaved": false,
	"usageProfileName": null,
	"script": "import sys\r\nfrom awsglue.transforms import *\r\nfrom awsglue.utils import getResolvedOptions\r\nfrom pyspark.context import SparkContext\r\nfrom awsglue.context import GlueContext\r\nfrom awsglue.job import Job\r\nfrom pyspark.sql.functions import col, count, avg, when, sum as spark_sum\r\nfrom datetime import datetime\r\n\r\n# ============================================\r\n# INITIALIZE GLUE CONTEXT\r\n# ============================================\r\n\r\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\r\nsc = SparkContext()\r\nglueContext = GlueContext(sc)\r\nspark = glueContext.spark_session\r\njob = Job(glueContext)\r\njob.init(args['JOB_NAME'], args)\r\n\r\n# ============================================\r\n# CONFIGURATION - UPDATE YOUR BUCKET NAME HERE\r\n# ============================================\r\n\r\nBUCKET_NAME = \"flights-data-lake-amruta\"  # âš ï¸ REPLACE WITH YOUR BUCKET NAME\r\nS3_RAW_PATH = f\"s3://{BUCKET_NAME}/raw/\"\r\nS3_PROCESSED_PATH = f\"s3://{BUCKET_NAME}/processed/\"\r\n\r\n# ============================================\r\n# LOG FUNCTION\r\n# ============================================\r\n\r\ndef log_message(message):\r\n    \"\"\"Helper function to log messages\"\"\"\r\n    print(f\"[GLUE JOB] {message}\")\r\n\r\n# ============================================\r\n# MAIN JOB\r\n# ============================================\r\n\r\ntry:\r\n    log_message(\"=\" * 60)\r\n    log_message(\"ğŸš€ FLIGHT AGGREGATION JOB STARTED\")\r\n    log_message(\"=\" * 60)\r\n    log_message(f\"â° Started at: {datetime.now()}\")\r\n    \r\n    # ============================================\r\n    # STEP 1: READ FROM S3\r\n    # ============================================\r\n    \r\n    log_message(\"\\nğŸ“¡ Reading raw flight data from S3...\")\r\n    log_message(f\"   Source: {S3_RAW_PATH}\")\r\n    \r\n    try:\r\n        # Read JSON files with multiline option for array format\r\n        df_raw = spark.read.option(\"multiline\", \"true\").json(S3_RAW_PATH)\r\n        raw_count = df_raw.count()\r\n        log_message(f\"âœ… Data loaded successfully\")\r\n        log_message(f\"   Total records: {raw_count}\")\r\n        log_message(f\"   Columns: {df_raw.columns}\")\r\n    except Exception as e:\r\n        log_message(f\"âŒ Error reading S3: {e}\")\r\n        raise\r\n    \r\n    # ============================================\r\n    # STEP 2: CLEAN DATA\r\n    # ============================================\r\n    \r\n    log_message(\"\\nğŸ”„ Cleaning data...\")\r\n    \r\n    df_clean = df_raw.filter(col(\"flight_id\").isNotNull())\r\n    clean_count = df_clean.count()\r\n    \r\n    log_message(f\"âœ… Removed nulls\")\r\n    log_message(f\"   Records after cleaning: {clean_count}\")\r\n    \r\n    # ============================================\r\n    # STEP 3: AGGREGATION BY AIRLINE\r\n    # ============================================\r\n    \r\n    log_message(\"\\nğŸ“Š Aggregating by airline...\")\r\n    \r\n    df_airline_agg = df_clean.groupBy(\"airline\").agg(\r\n        count(\"*\").alias(\"total_flights\"),\r\n        spark_sum(when(col(\"status\") == \"on_time\", 1).otherwise(0)).alias(\"on_time_count\"),\r\n        spark_sum(when(col(\"status\") == \"delayed\", 1).otherwise(0)).alias(\"delayed_count\"),\r\n        spark_sum(when(col(\"status\") == \"cancelled\", 1).otherwise(0)).alias(\"cancelled_count\"),\r\n        spark_sum(when(col(\"status\") == \"scheduled\", 1).otherwise(0)).alias(\"scheduled_count\")\r\n    ).orderBy(\"total_flights\", ascending=False)\r\n    \r\n    airline_count = df_airline_agg.count()\r\n    log_message(f\"âœ… Airline aggregation complete\")\r\n    log_message(f\"   Total airlines: {airline_count}\")\r\n    \r\n    # ============================================\r\n    # STEP 4: AGGREGATION BY STATUS\r\n    # ============================================\r\n    \r\n    log_message(\"\\nğŸ“Š Aggregating by flight status...\")\r\n    \r\n    df_status_agg = df_clean.groupBy(\"status\").agg(\r\n        count(\"*\").alias(\"count\")\r\n    ).orderBy(\"count\", ascending=False)\r\n    \r\n    log_message(f\"âœ… Status aggregation complete\")\r\n    \r\n    # ============================================\r\n    # STEP 5: AGGREGATION BY ROUTE\r\n    # ============================================\r\n    \r\n    log_message(\"\\nğŸ“Š Aggregating by route...\")\r\n    \r\n    df_route_agg = df_clean.groupBy(\"departure\", \"arrival\").agg(\r\n        count(\"*\").alias(\"total_flights\"),\r\n        spark_sum(when(col(\"status\") == \"delayed\", 1).otherwise(0)).alias(\"delayed_count\")\r\n    ).orderBy(\"total_flights\", ascending=False)\r\n    \r\n    route_count = df_route_agg.count()\r\n    log_message(f\"âœ… Route aggregation complete\")\r\n    log_message(f\"   Total routes: {route_count}\")\r\n    \r\n    # ============================================\r\n    # STEP 6: CREATE SUMMARY METRICS\r\n    # ============================================\r\n    \r\n    log_message(\"\\nğŸ“ˆ Creating summary metrics...\")\r\n    \r\n    total_flights = df_clean.count()\r\n    on_time_count = df_clean.filter(col(\"status\") == \"on_time\").count()\r\n    delayed_count = df_clean.filter(col(\"status\") == \"delayed\").count()\r\n    cancelled_count = df_clean.filter(col(\"status\") == \"cancelled\").count()\r\n    scheduled_count = df_clean.filter(col(\"status\") == \"scheduled\").count()\r\n    \r\n    on_time_percentage = (on_time_count / total_flights * 100) if total_flights > 0 else 0\r\n    delayed_percentage = (delayed_count / total_flights * 100) if total_flights > 0 else 0\r\n    cancelled_percentage = (cancelled_count / total_flights * 100) if total_flights > 0 else 0\r\n    \r\n    log_message(f\"âœ… Metrics calculated:\")\r\n    log_message(f\"   Total flights: {total_flights}\")\r\n    log_message(f\"   On-time: {on_time_count} ({on_time_percentage:.1f}%)\")\r\n    log_message(f\"   Delayed: {delayed_count} ({delayed_percentage:.1f}%)\")\r\n    log_message(f\"   Cancelled: {cancelled_count} ({cancelled_percentage:.1f}%)\")\r\n    log_message(f\"   Scheduled: {scheduled_count}\")\r\n    \r\n    # ============================================\r\n    # STEP 7: WRITE RESULTS TO S3\r\n    # ============================================\r\n    \r\n    log_message(\"\\nğŸ’¾ Writing aggregated results to S3...\")\r\n    \r\n    # Write airline aggregation\r\n    airline_output_path = f\"{S3_PROCESSED_PATH}airline_aggregation/\"\r\n    df_airline_agg.repartition(1).write.mode(\"overwrite\").json(airline_output_path)\r\n    log_message(f\"âœ… Airline aggregation saved\")\r\n    \r\n    # Write status aggregation\r\n    status_output_path = f\"{S3_PROCESSED_PATH}status_aggregation/\"\r\n    df_status_agg.repartition(1).write.mode(\"overwrite\").json(status_output_path)\r\n    log_message(f\"âœ… Status aggregation saved\")\r\n    \r\n    # Write route aggregation\r\n    route_output_path = f\"{S3_PROCESSED_PATH}route_aggregation/\"\r\n    df_route_agg.repartition(1).write.mode(\"overwrite\").json(route_output_path)\r\n    log_message(f\"âœ… Route aggregation saved\")\r\n    \r\n    # ============================================\r\n    # STEP 8: SHOW RESULTS\r\n    # ============================================\r\n    \r\n    log_message(\"\\n\" + \"=\" * 60)\r\n    log_message(\"ğŸ“Š AGGREGATION RESULTS\")\r\n    log_message(\"=\" * 60)\r\n    \r\n    log_message(\"\\nâœˆï¸ Top Airlines by Flight Count:\")\r\n    df_airline_agg.show(10, truncate=False)\r\n    \r\n    log_message(\"\\nğŸ“ˆ Flight Status Distribution:\")\r\n    df_status_agg.show(truncate=False)\r\n    \r\n    log_message(\"\\nğŸ›« Top Routes:\")\r\n    df_route_agg.show(10, truncate=False)\r\n    \r\n    # ============================================\r\n    # COMPLETION\r\n    # ============================================\r\n    \r\n    log_message(\"\\n\" + \"=\" * 60)\r\n    log_message(\"âœ… FLIGHT AGGREGATION JOB COMPLETED SUCCESSFULLY!\")\r\n    log_message(\"=\" * 60)\r\n    log_message(f\"â° Completed at: {datetime.now()}\")\r\n    log_message(f\"ğŸ“ Results saved to: {S3_PROCESSED_PATH}\")\r\n    log_message(\"   - airline_aggregation/\")\r\n    log_message(\"   - status_aggregation/\")\r\n    log_message(\"   - route_aggregation/\")\r\n    \r\nexcept Exception as e:\r\n    log_message(f\"\\nâŒ ERROR IN JOB: {str(e)}\")\r\n    log_message(f\"   Exception type: {type(e).__name__}\")\r\n    import traceback\r\n    log_message(f\"   Traceback: {traceback.format_exc()}\")\r\n    raise\r\n\r\nfinally:\r\n    # ============================================\r\n    # COMMIT JOB\r\n    # ============================================\r\n    \r\n    job.commit()\r\n    log_message(\"\\nğŸ”„ Glue job committed\")"
}